<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description"
        content="This years event will be hosted in Athlone, at the recently established Technological University of the Shannon Midlands campus.">

    <!-- Google / Search Engine Tags -->
    <meta itemprop="name" content="ICSC2022 Conference">
    <meta itemprop="description"
        content="This years event will be hosted in Athlone, at the recently established Technological University of the Shannon Midlands campus.">
    <meta itemprop="image" content="https://csound.com/icsc2022/img/code.JPG">

    <!-- Facebook Meta Tags -->
    <meta property="og:url" content="https://csound.com/icsc2022">
    <meta property="og:type" content="website">
    <meta property="og:title" content="ICSC2022 Conference">
    <meta property="og:description"
        content="This years event will be hosted in Athlone, at the recently established Technological University of the Shannon Midlands campus.">
    <meta property="og:image:" content="https://csound.com/icsc2022/img/code.JPG">
    <meta property="og:image:secure_url" content="https://csound.com/icsc2022/img/code.JPG">

    <!-- Twitter Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ICSC2022 Conference">
    <meta name="twitter:description"
        content="This years event will be hosted in Athlone, at the recently established Technological University of the Shannon Midlands campus.">
    <meta name="twitter:image" content="https://csound.com/icsc2022/img/code.JPG">
    <title>ICSC2022 Conference</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- icsc2017 styles -->
    <link href="css/style.css" rel="stylesheet">
    <!-- Montserrat typo -->
    <link href="css/fonts.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="shortcut icon" href="img/favicon.ico" />
</head>

<body>
    <header>
        <nav class="navbar navbar-default">
          <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="https://csound.com/"><img class="img-responsive" src="./img/Csound_Logo22.png"
                  alt="ICSC2022"></a>
            </div>
    
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
              <ul class="nav navbar-nav">
                <li><a href="./index.html#about">About</a></li>
                <li class="dropdown">
                  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Program <span class="caret"></span></a>
                  <ul class="dropdown-menu">
                    <li><a href="./program_list.html">Conference Program</a></li>
                    <li><a href="./keynotes.html">Keynotes</a></li>
                    <li><a href="./abstracts.html">Proceedings</a></li>
                    <li><a href="./workshops.html">Workshops</a></li>
                    <li><a href="./music.html">Music</a></li>
                  </ul>
                </li>
    
                <!-- <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Events <span class="caret"></span></a>
                    <ul class="dropdown-menu">
                      <li><a href="./concert.html">Pre-conference Concert</a></li>
                      <li><a href="./concerts.html">Concerts</a></li>
                      <li><a href="./workshops.html">Workshops</a></li>
                      <li><a href="./closing_event.html">Closing Event</a></li>
                    </ul>
                  </li> -->
                <!-- <li><a href="#keynotes">Keynotes</a></li> -->
                <li><a href="./index.html#location">Location</a></li>
    
                <li class="dropdown">
                  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true"
                    aria-expanded="false">Submit <span class="caret"></span></a>
                  <ul class="dropdown-menu">
                    <li><a href="./index.html#callforPapers">Papers</a></li>
                    <li><a href="./index.html#callforMusic">Music</a></li>
                    <li><a href="./index.html#callforInstallations">Installations</a></li>
                    <li><a href="./index.html#callforWorkshop">Workshops</a></li>
                  </ul>
                </li>
                <li><a href="#dates">Dates</a></li>
                <li><a href="#register">Register</a></li>
              </ul>
    
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container-fluid -->
        </nav>
      </header>

    <div class="bgimg-2">
        <div class="caption">
            <span class="border" style="background-color:transparent;font-size:40px;color: #f7f7f7;">PROCEEDINGS</span>
        </div>
    </div>

    <div class="content">
        <div class="container">


            <!-- <p>The conference proceedings are available in PDF format <a href="./proceedings/ICSC2017_proceedings.pdf">here</a>.</p>
	<p>&nbsp;</p> -->

            <h2>Abstracts</h2>

            <div class="keynotes">

                <!-- ======================= Session 1 ======================= -->

                <h3 id="session_1">Session 1</h3>

                <p id="Jiacomini" class="paper">Developing Cabbage Plugins For Composition and Sound Design and Sharing
                    Them Online </p>
                <p class="author">Caio Jiacomini <span class="pdf"><a href="./proceedings/Developing Cabbage Plugins For Composition and Sound Design and Sharing Them Online.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        In 2020 I discovered Csound. Using the FLOSS Manual, I started teaching myself about this
                        amazing program.
                        With Cabbage, I realized I could make my own plugins and distribute them on the internet.
                        My goal was to create custom tools for my own composition and sound design work, and be able to
                        share both
                        my musical creations and the tools I designed to create them. The result of this work was
                        Vendaval,
                        Granulera, and Cristalera. This paper will present a detailed overview of these Cabbage plugins,
                        and share my experience and advice about distributing them through the itch.io storefront
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, Cabbage, Plugins, Distribution, Granular
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
		  <dd>
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_1a_Cherny-Chesnokov-Rogozinsky_1080.mp4">1080</a> &ndash; 
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_1a_Cherny-Chesnokov-Rogozinsky_720.mp4">720</a> &ndash; 
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_1a_Cherny-Chesnokov-Rogozinsky_450.mp4">450</a>
		  </dd> -->
                </dl>

                <p id="Vittoria" class="paper">Educational Tools for Csound</p>
                <p class="author">Gianni Della Vittoria<span class="pdf"><a href="./proceedings/Educational Tools for Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        This paper presents a work platform aimed at simplifying the musical
                        composition process with Csound for students and beginners.
                        The tools developed for this purpose aim to reduce the distraction that comes
                        from having to carry out intermediate tasks that could be automated. They concern
                        the edi- tor's text expansion, automatic GUI and plotting, fast syntax for operations
                        with arrays, python-style list comprehension, multichannel expansion for Csound opcodes.
                        Although initially designed for the beginner, these tools may also prove useful for
                        experienced users should they wish to evaluate these procedures with these tools.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        workflow, text expansion, compositional tools, fast syntax, GUI, multichannel expansion, arrays,
                        list comprehension
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
		  <dd>
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_1b_Senna-Nava_1080.mp4">1080</a> &ndash; 
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_1b_Senna-Nava_720.mp4">720</a> &ndash; 
		  <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_1b_Senna-Nava_450.mp4">450</a>
		  </dd> -->
                </dl>

                <p id="ffitch1" class="paper">New Arduino Opcodes to Simplify the Streaming of Sensor and Controller
                    Data to Csound </p>
                <p class="author">John ffitch and Richard Boulanger<span class="pdf"><a href="./proceedings/New Arduino Opcodes to Simplify the Streaming of Sensor and Controller Data to Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        An alternative communication mechanism between the Arduino and
                        Csound is proposed and described in detail, with simple examples.
                        Comments on this design and possible developments and enhancements are sought.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, Arduino, UNO-R3, sensors, controllers
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
              <dd>
              <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_1b_Senna-Nava_1080.mp4">1080</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_1b_Senna-Nava_720.mp4">720</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_1b_Senna-Nava_450.mp4">450</a>
              </dd> -->
                </dl>

                <p id="ffitch2" class="paper">New Opcodes for MIDI CC Preset Banks and MIDI Note-on Toggles for Csound
                    in the Bela, Csound in the Nebulae, and Csound in General</p>
                <p class="author">John ffitch and Richard Boulanger<span class="pdf"><a href="./proceedings/New Opcodes for MIDI CC Preset Banks and MIDI Note-on Toggles for Csound in the Bela, Csound in the Nebulae, and Csound in General.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        In Csound, designing a MIDI synth that could store and recall MIDI
                        Continuous Controller (CC) settings on the fly (MIDI presets),
                        or turn a specific MIDI note-on message into an on/off toggle that
                        would turn a Reverb, Flanger, or Distortion effect on or off are
                        quite basic design needs that, until now, have required some pretty
                        ingenious, advanced, and sometimes quite convoluted coding tricks
                        to do the job. Some solutions use widgets and functions in Cabbage,
                        CsoundQt, or Blue, but what if you not using Cabbage, CsoundQt or Blue,
                        or what if you are not working on an OS, or in an Application, or
                        on an embedded computing platform that supports them such as the
                        Bela, the Qu-bit Nebulae, or Chrome, Safari, Firefox? To address this
                        general need, a new family of counting opcodes cntCreate, cntCycles,
                        cntDelete, cntRead, cntReset, cntState, and a new family of MIDI
                        controller opcodes ctrlpreset, ctrlprint, ctrlsave, ctrlselect have
                        been added to Csound. In this paper, a discussion of their design,
                        and examples of their use in general Csound and in Csound running
                        on the Bela will be presented.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, MIDI, controller, preset, toggle
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
              <dd>
              <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_1b_Senna-Nava_1080.mp4">1080</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_1b_Senna-Nava_720.mp4">720</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_1b_Senna-Nava_450.mp4">450</a>
              </dd> -->
                </dl>

                <p id="ffitch3" class="paper">Modeling a ’Classic’ Hardware Sequencer in Csound: The Design and Use of
                    the sequ Opcode</p>
                <p class="author">John ffitch and Richard Boulanger<span class="pdf"><a href="./proceedings/Modeling a ‘Classic’ Hardware Sequencer in Csound -The Design and Use of the sequ Opcode.pdf" ><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        Over the years, there have been many instruments,
                        designed and shared, that model the ’classic’ analog
                        step-sequencer. Some used the table opcodes, some did
                        it with Gens, some employed score macros, and score
                        commands, and others simply copy-pasted lines in the note- list.
                        More recently, impressive sequencer instruments are being
                        built with arrays, schedule, and event, and schedkwhen.
                        These designs have ranged from the simple to the sublime
                        and reveal many wonderful and inspiring approaches.
                        All are worthy of study and imitation. Still, beginners
                        always ask, ”How can you do sequencing in Csound?”
                        This question often leads into a deeper dive than they
                        are ready for. Or they ask, ”Does Csound have a sequencer
                        opcode?” Until recently, the answer to that question was
                        ”no”, but now the answer is ”yes!”. This paper will introduce
                        the sequ opcode, discuss how it was designed, show how it works,
                        and showcase some of the novel features, and the more esoteric
                        possibilities, associated with it’s unique design.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, sequencer, sequ
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
              <dd>
              <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_1b_Senna-Nava_1080.mp4">1080</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_1b_Senna-Nava_720.mp4">720</a> &ndash; 
              <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_1b_Senna-Nava_450.mp4">450</a>
              </dd> -->
                </dl>
                <hr>

            <!-- ======================= Session 2 ======================= -->

            <h3 id="session_2">Session 2</h3>

            <p id="Lazzarini" class="paper">A Just-in-Time Compiler for Csound Opcodes </p>
            <p class="author">Victor Lazzarini<span class="pdf"><a href="./proceedings/A Just-in-Time Compiler for Csound Opcodes.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span> </p>
            <dl>
                <dt>Abstract</dt>
                <dd>
                    This paper inroduces a work-in-progress project targeting the
                    development of a user-defined opcode just-in-time compiler.
                    It describes the newly introduced module compiler which can take
                    C or C++ code, compile it and make it availble inside a running
                    instance of Csound. The principles of a C++ opcode object factory
                    and its applications are also discussed. The direction of travel
                    leading to the completion of a UDO compiler is outlined.
                </dd>
                <dt>Keywords</dt>
                <dd>
                    Just-in-time compilers, extending Csound
                </dd>
                <!-- <dt>Video of the presentation</dt>
        <dd>
        <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_2a_Sigurdsson_1080.mp4">1080</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_2a_Sigurdsson_720.mp4">720</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_2a_Sigurdsson_450.mp4">450</a>
        </dd>
        </dl> -->

                <p id="ffitch4" class="paper">The Design and Use of Minimal7: Creating Subsets of Csound for
                    Embedded Applications </p>
                <p class="author">John ffitch and Richard Boulanger<span class="pdf"><a href="./proceedings/The Design and Use of Minimal7 - Creating Subsets of Csound for Embedded Applications.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        There have been complaints of ”opcode bloat” with Csound,
                        especially when embedding an audio application into a small
                        devices. The Minimal7 system offers a solution by automating
                        the process of only including the opcodes and fgens that are
                        actually used in a customised Csound system. and not ”all” of
                        Csound. In the following paper, the mechanism for this process
                        is explained, and a simple example of the work-flow is presented.
                        This is followed by a description of the limitations of the
                        current version and suggestions of what could be done to a
                        generate even smaller customised versions of Csound.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, Embedding, Customised
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
        <dd>
        <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_2b_Jure-Yi_1080.mp4">1080</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_2b_Jure-Yi_720.mp4">720</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_2b_Jure-Yi_450.mp4">450</a>
        </dd>
        </dl> -->


                    <p id="Escobar" class="paper">Analysis, DSP and Composition </p>
                    <p class="author">Emiliano del Cerro Escobar</p>
                    <dl>
                        <dt>Abstract</dt>
                        <dd>
                            This paper presents the process of a musical composition (Resemblance) based on the
                            analysis of children's songs and the use of the results of this analysis to produce
                            a new work using Neural Nets, Artificial Inteligence, Grammars and Digital Signal
                            Processing.
                            The idea of the composition came from the theory enunciated by Noam Chomsky that
                            indicates
                            how children recognize timbre and contour of melodic songs before semantic meaning of
                            language,
                            as well as the consideration of music as natural language. The concept of music as
                            natural
                            language allows the use of concepts and algorithms derived from
                            Computer Science and Artificial Intelligence.
                        </dd>
                        <dt>Keywords</dt>
                        <dd>
                            Musical Analysis, Resynthesis, Audio DSP. Csound Composition
                        </dd>
                        <!-- <dt>Video of the presentation</dt>
            <dd>
            <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_2b_Jure-Yi_1080.mp4">1080</a> &ndash; 
            <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_2b_Jure-Yi_720.mp4">720</a> &ndash; 
            <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_2b_Jure-Yi_450.mp4">450</a>
            </dd>
            </dl> -->
                    <hr>
                <!-- ======================= Session 3 ======================= -->

                <h3 id="session_3">Session 3</h3>

                <p id="Gasperini" class="paper">Csound and Python: A State of the Art Survey </p>
                <p class="author">Marco Gasperini and Giuseppe Ernandez</p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        The aim of the authors is to present a brief survey on the state of the art and a
                        short
                        tutorial for musicians on the chances given by the interaction between Csound and
                        the Python
                        programming languages regarding the field of algorithmic composition. Some examples
                        using
                        historical models have been developed in particular an environ- ment for generating
                        John Cage's
                        Imaginary Lanscape n° 5 variants and another to simulate James Tenney'Four
                        Stochastic Studies grammar.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Python, Algorithmic Score Generation, Electronic Music Teaching, John Cage, James
                        Tenney.
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
<dd>
<a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_3a_Boenn_1080.mp4">1080</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_3a_Boenn_720.mp4">720</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_3a_Boenn_450.mp4">450</a>
</dd> -->
                </dl>

                <p id="Zhang" class="paper">Using a Waveguide to Model the Pipa in Csound</p>
                <p class="author">Ningxin Zhang<span class="pdf"><a href="./proceedings/Using a Waveguide to Model the Pipa in Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        Csound offers a huge set of tools for composers and sound designers.
                        The author is a sound designer, electroacoustic composer, and
                        classically-trained pipa player who was especially inspired by the
                        sound of a number of Csound’s waveguide opcodes, and many of the physically
                        modeled Csound instruments. Immediately, the author used them in an
                        attempt to imitate the sound of the pipa. However, the result was
                        quite different from the acoustic pipa tone and thus led to the research
                        presented in this paper. What is shown here is how, in order to simulate
                        a more convincing pipa, the author needed to follow physical modeling
                        practice, and hand code the filters mathematically.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        Csound, Pipa, Waveguide, Karplus-Strong
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
    <dd>
    <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_3a_Boenn_1080.mp4">1080</a> &ndash; 
    <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_3a_Boenn_720.mp4">720</a> &ndash; 
    <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_3a_Boenn_450.mp4">450</a>
    </dd> -->
                </dl>

                <p id="Brandtsegg" class="paper">Rhythmic Synchronization of Events based on OSC Data from
                    an External Source </p>
                <p class="author">Øyvind Brandtsegg<span class="pdf"><a href="./proceedings/Rhythmic Synchronization of Events based on OSC Data from an External Source.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        OSC messages is an efficient and versatile manner in which to communicate between
                        Csound and other software.
                        An inherent drawback of using network communications is the potential for timing
                        jitter.
                        An event displacement of just a few a few milliseconds will in many cases be
                        perceived as a problem for
                        music performance. To alleviate these potential problems, one can use different
                        methods for time
                        stamping each OSC message, and the receiving module can use this for rhythmically
                        precise synchronization
                        when playing the events. The current article explores a method for such rhythmical
                        synchronization within Csound.
                    </dd>
                    <dt>Keywords</dt>
                    <dd>
                        OSC, Python, Rhythm, Timing and Synchronization
                    </dd>
                    <!-- <dt>Video of the presentation</dt>
        <dd>
        <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_3a_Boenn_1080.mp4">1080</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_3a_Boenn_720.mp4">720</a> &ndash; 
        <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_3a_Boenn_450.mp4">450</a>
        </dd> -->
                </dl>

            <!-- ======================= Session 4 ======================= -->

            <hr>

            <h3 id="session_4">Session 4</h3>

            <p id="Larrea" class="paper">New Utility Classes and Sketches for Developers and Sound
                Designers in CsoundUnity </p>
            <p class="author">Mateo Larrea and Caio Jiacomini<span class="pdf"><a href="./proceedings/New Utility Classes and Sketches for Developers and Sound Designers in CsoundUnity.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
            <dl>
                <dt>Abstract</dt>
                <dd>
                    TheCsoundUnity wrapper brings the realtime synthesis and signal processing power of
                    Csound
                    to applications created with Unity. Despite the various benefits that it provides,
                    the lack
                    of an extended set of examples and/or tutorials presents a challenge for those who
                    are new
                    to the workflow. In the following paper, we present a series of C# utility classes
                    that will
                    facilitate the creation of new models and applications by showing what is possible.
                    These i
                    nclude scripts/classes that assist in the formatting of Channel and ScoreEvent data,
                    getting
                    Transform and RigidBody data, establishing trajectories for the spatialization of
                    Audio
                    Sources, processing spectrum data for audio reactivity, timing events based on
                    mathematical
                    sequences, processing real-time input from a microphone or AudioClip, and
                    incorporating
                    haptics into a list of potential interactions. Essentially, this collection aims to
                    exhibit
                    an accessible interface for those who are not Unity or Csound experts - abstracting
                    repetitive methods and providing a layout for the further development of ‘sketches’
                    and fully-implemented applications.
                </dd>

                <dt>Keywords</dt>
                <dd>
                    CsoundUnity, C# Classes, Csound, Unity

                </dd>
                <!-- <dt>Video of the presentation</dt>
<dd>
<a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
</dd>
</dl> -->

                <p id="Sodre" class="paper">Designing VR Applications with CsoundUnity </p>
                <p class="author">Pedro Sodre<span class="pdf"><a href="./proceedings/Designing VR Applications with CsoundUnity.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                <dl>
                    <dt>Abstract</dt>
                    <dd>
                        This paper presents two interactive music systems built for the Oculus
                        Quest that use the CsoundUnity package. The first system explores different
                        ways to control Csound instruments and samples by interacting with 3D objects
                        using object collision and the grip buttons of the VR controller. The second
                        system transforms Boulanger’s classic “Trapped In Convert” into an interactive
                        system that allows users to play and spatialize adaptations of the original
                        Csound instruments used in the piece - to remix it and recompose it and play
                        along with it.
                    </dd>

                    <dt>Keywords</dt>
                    <dd>
                        Csound, Unity, CsoundUnity, VR

                    </dd>
                    <!-- <dt>Video of the presentation</dt>
<dd>
<a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
<a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
</dd>
</dl> -->

                    <p id="Samsurya" class="paper">Realtime Audio Raytracing and Occlusion in Csound and
                        Unity </p>
                    <p class="author">Bilkent Samsurya<span class="pdf"><a href="./proceedings/Realtime Audio Raytracing and Occlusion in Csound and Unity.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                    <dl>
                        <dt>Abstract</dt>
                        <dd>
                            Extensive research has gone into the development of interactive virtual
                            environment
                            tools but its studies on audio technology are limited. There are many
                            acoustical
                            modeling tools which can be ap- plied to audio processing for virtual
                            environments
                            and the integration of Csound and Unity presents an opportunity to explore
                            this area
                            of research. This thesis describes an implementation of a realtime ray
                            tracing and
                            sound occlusion system to model acoustics in a virtual environment. The game
                            engine
                            Unity is chosen for the environment and Csound is the sound system chosen
                            for the
                            audio processing component. In the following paper, the mechanisms for which
                            the
                            process is outlined and the workflow is presented. A test to evaluate the
                            effectiveness
                            of the system is conducted. This is followed by a description of its
                            limitations and proposal for a revised model.
                        </dd>

                        <dt>Keywords</dt>
                        <dd>
                            Csound, Unity, Raytracing, Occlusion

                        </dd>
                        <!-- <dt>Video of the presentation</dt>
    <dd>
    <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
    <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
    <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
    </dd>
    </dl> -->
                                        <!-- ======================= Session 5 ======================= -->

                                        <hr>
                                        <h3 id="session_5">Session 5</h3>

                                        <p id="Janevska" class="paper">Implementing Andy Farnell’s ‘bouncing ball’ in
                                            Csound </p>
                                        <p class="author">Marijana Janevska, James Anderson and Joachim Heintz<span class="pdf"><a href="./proceedings/Implementing Andy Farnell’s ‘bouncing ball’ in Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                                        <dl>
                                            <dt>Abstract</dt>
                                            <dd>
                                                This paper discusses the Csound implementation of the bouncing ball
                                                model from Andy Farnell's Designing Sound [Farnell 2010]. We will
                                                consider Farnell’s approach to sound design with Pure Data, then
                                                present two possible procedures for extending this model to and
                                                improving it in Csound. Finally, we will present creative examples
                                                of varying and employing the model in a musical context.
                                            </dd>

                                            <dt>Keywords</dt>
                                            <dd>
                                                Csound, CsoundQt, Pure Data, Hannover, Incontri, FMSBW, Andy Farnell,
                                                Designing Sound

                                            </dd>
                                            <!-- <dt>Video of the presentation</dt>
                        <dd>
                        <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
                        <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
                        <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
                        </dd>
                        </dl> -->

                                            <p id="Phillipe" class="paper">HYPERCURVE - A hybrid curve forge in Csound
                                            </p>
                                            <p class="author">Johann Phillipe and Jacopo Greco d’Alceo<span class="pdf"><a href="./proceedings/HYPERCURVE - An hybrid curve forge in Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                                            <dl>
                                                <dt>Abstract</dt>
                                                <dd>
                                                    HYPERCURVE is a new library designed to combine different
                                                    curve algorithms inside one function table. It has been
                                                    thought as a tool for musicians looking to shape precisely
                                                    their envelopes and function tables. The library is exposed
                                                    to several environments, like Csound, Faust, Lua and C++.
                                                </dd>

                                                <dt>Keywords</dt>
                                                <dd>
                                                    Curve,Perception,Csound,Shape,Envelop,Waveform,Control

                                                </dd>
                                                <!-- <dt>Video of the presentation</dt>
                            <dd>
                            <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
                            <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
                            <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
                            </dd>
                            </dl> -->

                                                <p id="Yang" class="paper">The road to electronic music education and
                                                    composition in China based on Csound </p>
                                                <p class="author">Wanjun Yang and Jinhao Han<span class="pdf"><a href="./proceedings/The road to electronic music education and composition in China based on Csound.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                                                <dl>
                                                    <dt>Abstract</dt>
                                                    <dd>
                                                        Using music programming for electronic music composition has
                                                        been an important way of
                                                        electronic music research and composition for more than half a
                                                        century, but how to
                                                        educate and promote it is a great problem for researchers. This
                                                        paper will discuss
                                                        the experiences and achievements of Chinese electronic musicians
                                                        in electronic music
                                                        education and composition with Csound. With the Sichuan
                                                        Conservatory of Music as
                                                        the object of analysis, we will explore how to combine new
                                                        technologies with the
                                                        essence of Chinese culture in electronic music composition and
                                                        composer training,
                                                        find new forms and explore the impact of the intermingling and
                                                        collision of different
                                                        cultures on the promotion of music art and technology.
                                                    </dd>

                                                    <dt>Keywords</dt>
                                                    <dd>
                                                        Csound, Chinese culture, teaching, composition, The Night of
                                                        Coding

                                                    </dd>
                                                    <!-- <dt>Video of the presentation</dt>
                                <dd>
                                <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
                                <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
                                <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
                                </dd>
                                </dl> -->

                                                    <!-- ======================= Session 6 ======================= -->

                                                    <hr>
                                                    <h3 id="session_6">Session 6</h3>

                                                    <p id="Boulanger" class="paper">Scanned Synthesis Then & Now – The
                                                        Design and Enhancement of Csound’s Scanned Opcodes </p>
                                                    <p class="author">Richard Boulanger and John ffitch<span class="pdf"><a href="./proceedings/Scanned Synthesis Then & Now – The Design and Enhancement of Csound’s Scanned Opcodes.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                                                    <dl>
                                                        <dt>Abstract</dt>
                                                        <dd>
                                                            Scanned Synthesis was introduced at the 2000 ICMC in Berlin.
                                                            The underlying algorithm was developed
                                                            by Max Mathews, ex- panded upon and coded into Csound by
                                                            Paris Smaragdis, and, over the years, enhanced
                                                            and expanded further by John ffitch. Recently, when working
                                                            to clarify the wording and improve the
                                                            examples in the Csound Manual, a number of questions arose
                                                            such as: ”what are the differences between
                                                            all the scanned opcodes?”; ”how do they interact with each
                                                            other?”, and ”how do the scanned opcodes
                                                            actually work under the hood?” While answering these
                                                            questions, and coding new examples,
                                                            the authors realized that there was room for further
                                                            improvement, and that some powerful
                                                            optional arguments could be added to support further sonic
                                                            exploration. In fact, where
                                                            the scanned opcodes started, and where they are today is
                                                            quite an inspiring story.
                                                            This paper will tell the story of the birth of scanu and
                                                            scans in the mind of Max Mathews,
                                                            and their current scanu2, scantable and scanmap capabilities
                                                            today.
                                                        </dd>

                                                        <dt>Keywords</dt>
                                                        <dd>
                                                            Csound, scanned, scanu, scanu2, scans, scanmap, gen44

                                                        </dd>
                                                        <!-- <dt>Video of the presentation</dt>
            <dd>
            <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
            <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
            <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
            </dd>
            </dl> -->

                                                        <p id="Walter" class="paper">Creating Modulation Matrices for
                                                            Modern Synthesizers and Effects in Csound and Cabbage </p>
                                                        <p class="author">Jonathon Walter<span class="pdf"><a href="./proceedings/Creating Modulation Matrices for Modern Synthesizers and Effects in Csound and Cabbage.pdf"><img src="./img/iconpdf.svg" alt="pdf"></a></span></p>
                                                        <dl>
                                                            <dt>Abstract</dt>
                                                            <dd>
                                                                When designing synthesizers and effects often the most
                                                                important and characteristic component
                                                                is its modulation capabilities. When looking at
                                                                commercial hardware such as pedals by Chase
                                                                Bliss, essentially every parameter can be modulated
                                                                internally, as well as controlled via MIDI and CV.
                                                                Alternatively, hardware such as Sequential’s Prophet 6
                                                                offers limited customizable modulation, which
                                                                helps establish the synthesizer’s signature sound.
                                                                Internal modulation presents an interesting problem
                                                                as one doesn’t want to limit the modulation capabilities
                                                                of the user, while also not sacrificing CPU.
                                                                One solution is to build all-encompassing internal
                                                                routing matrices into your plugins.
                                                                The following paper will explain how to create a routing
                                                                matrix for synthesizers and effects
                                                                inspired by the one in Ableton’s wavetable synthesizer.
                                                            </dd>

                                                            <dt>Keywords</dt>
                                                            <dd>
                                                                Csound, Cabbage, ntrpol, Modulation, Matrix, Plugins

                                                            </dd>
                                                            <!-- <dt>Video of the presentation</dt>
                <dd>
                <a href="http://www.eumus.edu.uy/eme/icsc2017/1080/ICSC2017_Session_4a_DiLiscia_1080.mp4">1080</a> &ndash; 
                <a href="http://www.eumus.edu.uy/eme/icsc2017/720/ICSC2017_Session_4a_DiLiscia_720.mp4">720</a> &ndash; 
                <a href="http://www.eumus.edu.uy/eme/icsc2017/450/ICSC2017_Session_4a_DiLiscia_450.mp4">450</a>
                </dd>
                </dl> -->



            </div>




            <p></p>

        </div>
    </div>

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-xs-8">
                    <a target="_blank" href="https://www.tus.ie/"><img class="img-responsive center-block tuslogo"
                            src="./img/TUS-Logo_Bilingual_Reverse-Duotone_RGB-2-e1646755043843.png" alt="TUS"></a>
                </div>
                <div class="col-xs-4" style="text-align:right;padding-top: 5%;">
                    <a class="contact" target="_blank" href="mailto:icsc2022.music@gmail.com">contact</a>
                </div>
            </div>
        </div>
    </footer>

 <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
 <!-- Include all compiled plugins (below), or include individual files as needed -->
 <script src="js/bootstrap.min.js"></script>
 <script>
   $(window).on('scroll', function () {

     if ($(window).scrollTop() >= 0) {
       $('header').addClass('fixed');
       //$('.page-header').addClass('hide-header');
     }
     else {
       $('header').removeClass('fixed');
       //$('.page-header').removeClass('hide-header');
     }
   });

   var coll = document.getElementsByClassName("collapsible");
   var i;

   for (i = 0; i < coll.length; i++) {
     coll[i].addEventListener("click", function () {
       this.classList.toggle("active");
       var content = this.nextElementSibling;
       if (content.style.display === "block") {
         content.style.display = "none";
       } else {
         content.style.display = "block";
       }
     });
   }
 </script>
</body>

</html>